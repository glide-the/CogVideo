import torch


ckpt_path = '/mnt/ceph/develop/jiawei/model_checkpoint/ckpts_2b_lora/lora-disney-09-10-16-05/1/mp_rank_00_model_states.pt'
 


from typing import Any, Dict


def get_state_dict(saved_dict: Dict[str, Any]) -> Dict[str, Any]:
    state_dict = saved_dict
    if "model" in saved_dict.keys():
        state_dict = state_dict["model"]
    if "module" in saved_dict.keys():
        state_dict = state_dict["module"]
    if "state_dict" in saved_dict.keys():
        state_dict = state_dict["state_dict"]
    return state_dict
 
 


 

lora_original_state_dict = get_state_dict(torch.load(ckpt_path, map_location="cpu", mmap=True))


ckpt_path = '/mnt/ceph/develop/jiawei/model_checkpoint/ckpts_2b_lora/lora-disney-09-09-21-10/1000/mp_rank_00_model_states.pt'
 



merge_original_state_dict = get_state_dict(torch.load(ckpt_path, map_location="cpu", mmap=True))
  




diff_keys = merge_original_state_dict.keys() - lora_original_state_dict.keys()
diff_keys


list(lora_original_state_dict.keys())


def reassign_query_key_value_inplace(key: str, state_dict: Dict[str, Any]):
    to_q_key = key.replace("query_key_value", "to_q")
    to_k_key = key.replace("query_key_value", "to_k")
    to_v_key = key.replace("query_key_value", "to_v")
    to_q, to_k, to_v = torch.chunk(state_dict[key], chunks=3, dim=0)
    state_dict[to_q_key] = to_q
    state_dict[to_k_key] = to_k
    state_dict[to_v_key] = to_v
    state_dict.pop(key)


def update_state_dict_inplace(state_dict: Dict[str, Any], old_key: str, new_key: str) -> Dict[str, Any]:
    state_dict[new_key] = state_dict.pop(old_key)



TRANSFORMER_KEYS_RENAME_DICT = {
    "transformer.final_layernorm": "norm_final",
    "transformer": "transformer_blocks",
    "attention": "attn1",
    "mlp": "ff.net",
    "dense_h_to_4h": "0.proj",
    "dense_4h_to_h": "2",
    ".layers": "",
    "dense": "to_out.0",
    "input_layernorm": "norm1.norm",
    "post_attn1_layernorm": "norm2.norm",
    "time_embed.0": "time_embedding.linear_1",
    "time_embed.2": "time_embedding.linear_2",
    "mixins.patch_embed": "patch_embed",
    "mixins.final_layer.norm_final": "norm_out.norm",
    "mixins.final_layer.linear": "proj_out",
    "mixins.final_layer.adaLN_modulation.1": "norm_out.linear",
}



PREFIX_KEY = "model.diffusion_model."
for key in list(merge_original_state_dict.keys()):
    new_key = key[len(PREFIX_KEY) :]
    for replace_key, rename_key in TRANSFORMER_KEYS_RENAME_DICT.items():
        new_key = new_key.replace(replace_key, rename_key)
    update_state_dict_inplace(merge_original_state_dict, key, new_key)


merge_original_state_dict.keys()



